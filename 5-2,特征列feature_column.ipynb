{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-2,特征列feature_column\n",
    "\n",
    "特征列 通常用于对结构化数据实施特征工程时候使用，图像或者文本数据一般不会用到特征列。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一，特征列用法概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用特征列可以将类别特征转换为one-hot编码特征，将连续特征构建分桶特征，以及对多个特征生成交叉特征等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要创建特征列，请调用 tf.feature_column 模块的函数。该模块中常用的九个函数如下图所示，所有九个函数都会返回一个 Categorical-Column 或一个 \n",
    "Dense-Column 对象，但却不会返回 bucketized_column，后者继承自这两个类。\n",
    "\n",
    "注意：所有的Catogorical Column类型最终都要通过indicator_column转换成Dense Column类型才能传入模型！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./data/特征列9种.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* numeric_column 数值列，最常用。\n",
    "\n",
    "\n",
    "* bucketized_column 分桶列，由数值列生成，可以由一个数值列出多个特征，one-hot编码。\n",
    "\n",
    "\n",
    "* categorical_column_with_identity 分类标识列，one-hot编码，相当于分桶列每个桶为1个整数的情况。\n",
    "\n",
    "\n",
    "* categorical_column_with_vocabulary_list 分类词汇列，one-hot编码，由list指定词典。\n",
    "\n",
    "\n",
    "* categorical_column_with_vocabulary_file 分类词汇列，由文件file指定词典。\n",
    "\n",
    "\n",
    "* categorical_column_with_hash_bucket 哈希列，整数或词典较大时采用。\n",
    "\n",
    "\n",
    "* indicator_column 指标列，由Categorical Column生成，one-hot编码\n",
    "\n",
    "\n",
    "* embedding_column 嵌入列，由Categorical Column生成，嵌入矢量分布参数需要学习。嵌入矢量维数建议取类别数量的 4 次方根。\n",
    "\n",
    "\n",
    "* crossed_column 交叉列，可以由除categorical_column_with_hash_bucket的任意分类列构成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二，特征列使用范例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是一个使用特征列解决Titanic生存问题的完整范例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "\n",
    "\n",
    "#打印日志\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "    print(info+'...\\n\\n')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================\n",
    "# 一，构建数据管道\n",
    "#================================================================================\n",
    "printlog(\"step1: prepare dataset...\")\n",
    "\n",
    "\n",
    "dftrain_raw = pd.read_csv(\"./data/titanic/train.csv\")\n",
    "dftest_raw = pd.read_csv(\"./data/titanic/test.csv\")\n",
    "\n",
    "dfraw = pd.concat([dftrain_raw,dftest_raw])\n",
    "\n",
    "def prepare_dfdata(dfraw):\n",
    "    dfdata = dfraw.copy()\n",
    "    dfdata.columns = [x.lower() for x in dfdata.columns]\n",
    "    dfdata = dfdata.rename(columns={'survived':'label'})\n",
    "    dfdata = dfdata.drop(['passengerid','name'],axis = 1)\n",
    "    for col,dtype in dict(dfdata.dtypes).items():\n",
    "        # 判断是否包含缺失值\n",
    "        if dfdata[col].hasnans:\n",
    "            # 添加标识是否缺失列\n",
    "            dfdata[col + '_nan'] = pd.isna(dfdata[col]).astype('int32')\n",
    "            # 填充\n",
    "            if dtype not in [np.object,np.str,np.unicode]:\n",
    "                dfdata[col].fillna(dfdata[col].mean(),inplace = True) #数值型均值替代\n",
    "            else:\n",
    "                dfdata[col].fillna('',inplace = True) #字符型空值替代\n",
    "    return(dfdata)\n",
    "\n",
    "dfdata = prepare_dfdata(dfraw)\n",
    "dftrain = dfdata.iloc[0:len(dftrain_raw),:]\n",
    "dftest = dfdata.iloc[len(dftrain_raw):,:]\n",
    "\n",
    "\n",
    "\n",
    "# 从 dataframe 导入数据 \n",
    "def df_to_dataset(df, shuffle=True, batch_size=32):\n",
    "    dfdata = df.copy()\n",
    "    if 'label' not in dfdata.columns:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(dfdata.to_dict(orient = 'list'))\n",
    "    else: \n",
    "        labels = dfdata.pop('label')\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dfdata.to_dict(orient = 'list'), labels))  \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dfdata))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "ds_train = df_to_dataset(dftrain)\n",
    "ds_test = df_to_dataset(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================\n",
    "# 二，定义特征列\n",
    "#================================================================================\n",
    "printlog(\"step2: make feature columns...\")\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "# 数值列\n",
    "for col in ['age','fare','parch','sibsp'] + [\n",
    "    c for c in dfdata.columns if c.endswith('_nan')]:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(col))\n",
    "\n",
    "# 分桶列\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "age_buckets = tf.feature_column.bucketized_column(age, \n",
    "             boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "feature_columns.append(age_buckets)\n",
    "\n",
    "# 类别列\n",
    "# 注意：所有的Catogorical Column类型最终都要通过indicator_column转换成Dense Column类型才能传入模型！！\n",
    "sex = tf.feature_column.indicator_column(\n",
    "      tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      key='sex',vocabulary_list=[\"male\", \"female\"]))\n",
    "feature_columns.append(sex)\n",
    "\n",
    "pclass = tf.feature_column.indicator_column(\n",
    "      tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      key='pclass',vocabulary_list=[1,2,3]))\n",
    "feature_columns.append(pclass)\n",
    "\n",
    "ticket = tf.feature_column.indicator_column(\n",
    "     tf.feature_column.categorical_column_with_hash_bucket('ticket',3))\n",
    "feature_columns.append(ticket)\n",
    "\n",
    "embarked = tf.feature_column.indicator_column(\n",
    "      tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      key='embarked',vocabulary_list=['S','C','B']))\n",
    "feature_columns.append(embarked)\n",
    "\n",
    "# 嵌入列\n",
    "cabin = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('cabin',32),2)\n",
    "feature_columns.append(cabin)\n",
    "\n",
    "# 交叉列\n",
    "pclass_cate = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "          key='pclass',vocabulary_list=[1,2,3])\n",
    "\n",
    "crossed_feature = tf.feature_column.indicator_column(\n",
    "    tf.feature_column.crossed_column([age_buckets, pclass_cate],hash_bucket_size=15))\n",
    "\n",
    "feature_columns.append(crossed_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================\n",
    "# 三，定义模型\n",
    "#================================================================================\n",
    "printlog(\"step3: define model...\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "  layers.DenseFeatures(feature_columns), #将特征列放入到tf.keras.layers.DenseFeatures中!!!\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(64, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================\n",
    "# 四，训练模型\n",
    "#================================================================================\n",
    "printlog(\"step4: train model...\")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "          validation_data=ds_test,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================================\n",
    "# 五，评估模型\n",
    "#================================================================================\n",
    "printlog(\"step5: eval model...\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metric(history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()\n",
    "\n",
    "plot_metric(history,\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_features (DenseFeature multiple                  64        \n",
    "_________________________________________________________________\n",
    "dense (Dense)                multiple                  3008      \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              multiple                  4160      \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              multiple                  65        \n",
    "=================================================================\n",
    "Total params: 7,297\n",
    "Trainable params: 7,297\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./data/5-2-01-模型评估.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"Python与算法之美\"下留言。作者时间和精力有限，会酌情予以回复。\n",
    "\n",
    "也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n",
    "\n",
    "![image.png](./data/Python与算法之美logo.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
